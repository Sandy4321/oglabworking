{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# IBM Watson OpenScale Lab instructions\n\nThis notebook should be run in a Watson Studio project, using with **Python 3.6 with Spark** runtime environment. **If you are viewing this in Watson Studio and do not see Python 3.6 with Spark in the upper right corner of your screen, please update the runtime now.** It requires service credentials for the following Cloud services:\n  * IBM Watson OpenScale\n  * Watson Machine Learning\n  \nIf you have a paid Cloud account, you may also provision a **Databases for PostgreSQL** or **Db2 Warehouse** service to take full advantage of integration with Watson Studio and continuous learning services. If you choose not to provision this paid service, you can use the free internal PostgreSQL storage with OpenScale, but will not be able to configure continuous learning for your model.\n\nThe notebook will train, create and deploy a Propensity to Buy Model, configure OpenScale to monitor that deployment, and inject seven days' worth of historical records and measurements for viewing in the OpenScale Insights dashboard.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Business Scenario", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "National Chemical Company (NCC) operates two plants plants in South Lousiana.  Both plants produce the same chemical.  Both plants use the same suppliers.  Both plants are managed by the same people.  The only difference between the two plants is age.  Plant A is brand new.  It opened less than a year ago.  Plant B is more than 20 years old.\n\nBad Yields cost NCC millions of dollars each year.  A bad yield just means that the final product produced by the factory does not meet quality standards.  Ideally, they would like to predict a bad yield a few days in advance, drill down to see why there is a prediction of a bad yield and make corrections.  To accomplish this, NCC turned to IBM and Watson.  \n\nIn this notebook, you will construct a machine learning model and deploy that model to a Watson Machine Learning Service.  This model is based on historical data and predicts the probability of a bad yield.  \n\nAfter the model is built and deployed, the notebook configures Watson Openscale.  Watson Openscale will allow NCC to monitor the accuracy of the model over-time and understand the key factors that cause  bad yields.  Knowing why a bad yield will occur allows the plant operators to make adjustments and prevent them from occuring.\n\nAnother key issue that NCC is worried about is the bad sensor readings in Plant B, the older plant.  They are concerned that the bad sensor readings will lead to invalid predictions.  Given that Plant A and B an should have a similar percentage of predicted Bad Yield yields, we will use the bias and fairness detection monitors inside Watson Openscale to correct bias that may occur because of the older sensors in Plant B.\n\n\n\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Package installation", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "!rm -rf $PIP_BUILD\n!pip install psycopg2-binary | tail -n 1\n!pip install --upgrade watson-machine-learning-client --no-cache | tail -n 1\n!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1\n!pip install --upgrade numpy --no-cache | tail -n 1\n!pip install --upgrade lime --no-cache | tail -n 1\n!pip install --upgrade SciPy --no-cache | tail -n 1", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "#### Provision services and configure credentials", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "If you have not already, provision an instance of IBM Watson OpenScale using the [OpenScale link in the Cloud catalog](https://cloud.ibm.com/catalog/services/ai-openscale).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "CLOUD_API_KEY = \"PFHEY2Po9KcARJqfUtnv75yvAHtawFzURnMWorJedhK7\"", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "Next you will need credentials for Watson Machine Learning. If you already have a WML instance, you may use credentials for it. To provision a new Lite instance of WML, use the [Cloud catalog](https://cloud.ibm.com/catalog/services/machine-learning), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your WML credentials into the cell below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "WML_CREDENTIALS ={\n  \"apikey\": \"uoUoBHKgrz-OPFGBmLNhQgy_BlHNPXCqyJYaR-5tGNGt\",\n  \"iam_apikey_description\": \"Auto-generated for key 9e155d75-e70d-40c7-96ee-dba3fe9a030d\",\n  \"iam_apikey_name\": \"Service credentials-1\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/97deeb0b7e78431438a00a04f20580b7::serviceid:ServiceId-755ca7bd-4d01-44b9-912d-7c05f9d81a11\",\n  \"instance_id\": \"67c0aed8-ed70-4029-a923-a585e83408c4\",\n  \"password\": \"b7a11f66-129c-44fc-a963-958e9e4f6452\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n  \"username\": \"9e155d75-e70d-40c7-96ee-dba3fe9a030d\"\n}", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "This lab can use Databases for PostgreSQL, Db2 Warehouse, or a free internal verison of PostgreSQL to create a datamart for OpenScale.\n\nIf you have previously configured OpenScale, it will use your existing datamart, and not interfere with any models you are currently monitoring. Do not update the cell below.\n\nIf you do not have a paid Cloud account or would prefer not to provision this paid service, you may use the free internal PostgreSQL service with OpenScale. Do not update the cell below.\n\nTo provision a new instance of Db2 Warehouse, locate [Db2 Warehouse in the Cloud catalog](https://cloud.ibm.com/catalog/services/db2-warehouse), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your Db2 Warehouse credentials into the cell below.\n\nTo provision a new instance of Databases for PostgreSQL, locate [Databases for PostgreSQL in the Cloud catalog](https://cloud.ibm.com/catalog/services/databases-for-postgresql), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your Databases for PostgreSQL credentials into the cell below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "DB_CREDENTIALS = None", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "__If you previously configured OpenScale to use the free internal version of PostgreSQL, you can switch to a new datamart using a paid database service.__ If you would like to delete the internal PostgreSQL configuration and create a new one using service credentials supplied in the cell above, set the __KEEP_MY_INTERNAL_POSTGRES__ variable below to __False__ below. In this case, the notebook will remove your existing internal PostgreSQL datamart and create a new one with the supplied credentials. __*NO DATA MIGRATION WILL OCCUR.*__", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "KEEP_MY_INTERNAL_POSTGRES = True", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# Run the notebook\n\nAt this point, the notebook is ready to run. You can either run the cells one at a time, or click the **Kernel** option above and select **Restart and Run All** to run all the cells.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Load and explore data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Load the training data from github", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "!rm df_training.csv\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_training.csv", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport json\nimport numpy as np\n\nspark = SparkSession.builder.getOrCreate()\npd_data = pd.read_csv(\"df_training.csv\", sep=\",\", header=0)\n#df_data = spark.read.csv(path=\"df_training.csv\", sep=\",\", header=True, inferSchema=True)\n#df_data.head()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "df_training=pd_data", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "pd_data.columns", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "pd_data['RPM_MEAN']=(np.random.randint(5000, 6000,pd_data.shape[0]))/1\npd_data['RPM_MIN']=(np.random.randint(5000, 6000,pd_data.shape[0]))/1\npd_data['RPM_MAX']=(np.random.randint(5000, 6000,pd_data.shape[0]))/1\npd_data['WS_001_CONC_MEAN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_001_CONC_MIN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_001_CONC_MAX']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['DMW_FLOW_MEAN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['DMW_FLOW_MIN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['DMW_FLOW_MAX']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['ALK_FLOW_MEAN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['ALK_FLOW_MAX']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['ALK_FLOW_MIN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_002_FLOW_MEAN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_002_FLOW_MIN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_002_FLOW_MAX']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_002_CONC_MEAN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_002_CONC_MIN']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\npd_data['WS_002_CONC_MAX']=(np.random.randint(80000, 100000,pd_data.shape[0]))/1000\n\n\n", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "pd_data['wookie']=(np.random.randint(1, 1000,pd_data.shape[0]))/1000\n", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "PLANT_B=pd_data[pd_data['PLANT_A'] ==0]\nPLANT_A=pd_data[pd_data['PLANT_A']==1]\nPLANT_B_0=PLANT_B[PLANT_B['BAD_YIELD']=='BAD']\nPLANT_B_1=PLANT_B[PLANT_B['BAD_YIELD']=='GOOD']\n#PLANT_B_1a=PLANT_B_1[PLANT_B_1['wookie']<=0.75]\n#PLANT_B_1b=PLANT_B_1[PLANT_B_1['wookie']>0.75]\n\n\n\nPLANT_B_1 = PLANT_B_1.copy()\n\nPLANT_B_1['BAD_YIELD'] = np.where(PLANT_B_1['wookie']<=0.000001, 'BAD', 'GOOD')", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "pd_data = PLANT_B_0.append([PLANT_B_1, PLANT_A])\n\npd_data=pd_data.drop(columns=['wookie'])", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "pd.crosstab(pd_data.PLANT_A, pd_data.BAD_YIELD).apply(lambda r: r/r.sum(), axis = 1)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "pd_data.shape\npd_data.head()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "df_data = spark.createDataFrame(pd_data)\ndf_data.head()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Explore data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "df_data.printSchema()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "print(\"Number of records: \" + str(df_data.count()))", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "# Create a model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "spark_df = df_data\n(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n\nMODEL_NAME = \"Yieldx Model\"\nDEPLOYMENT_NAME = \"Yieldx Model\"\n\nprint(\"Number of records for training: \" + str(train_data.count()))\nprint(\"Number of records for evaluation: \" + str(test_data.count()))\n\nspark_df.printSchema()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model\nfrom pyspark.ml import linalg\n\n", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "si_Label = StringIndexer(inputCol=\"BAD_YIELD\", outputCol=\"label\").fit(spark_df)\nlabel_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_Label.labels)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "pd_data.columns", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "va_features = VectorAssembler(inputCols=['WS_001_FLOW_MEAN', 'WS_001_FLOW_MIN', 'WS_001_FLOW_MAX',\n       'WS_001_CONC_MEAN', 'WS_001_CONC_MIN', 'WS_001_CONC_MAX',\n       'DMW_FLOW_MEAN', 'DMW_FLOW_MIN', 'DMW_FLOW_MAX', 'ALK_FLOW_MEAN',\n       'ALK_FLOW_MIN', 'ALK_FLOW_MAX', 'RPM_MEAN', 'RPM_MIN', 'RPM_MAX', 'PLANT_A'], outputCol=\"features\")", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "from pyspark.ml.classification import RandomForestClassifier\nclassifier = RandomForestClassifier(featuresCol=\"features\")\n\npipeline = Pipeline(stages=[ si_Label, va_features, classifier, label_converter])\nmodel = pipeline.fit(train_data)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "predictions = model.transform(test_data)\nevaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\narea_under_curve = evaluatorDT.evaluate(predictions)\n\n#default evaluation is areaUnderROC\nprint(\"areaUnderROC = %g\" % area_under_curve)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "# Save and deploy the model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from scipy import sparse\nfrom scipy import linalg", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient \nimport json \n\n\n\nwml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "### Remove existing model and deployment", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "model_deployment_ids = wml_client.deployments.get_uids()\nfor deployment_id in model_deployment_ids:\n    deployment = wml_client.deployments.get_details(deployment_id)\n    model_id = deployment['entity']['deployable_asset']['guid']\n    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n        print('Deleting deployment id', deployment_id)\n        wml_client.deployments.delete(deployment_id)\n        print('Deleting model id', model_id)\n        wml_client.repository.delete(model_id)\nwml_client.repository.list_models()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "model_props = {\n    wml_client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n    wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n    wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n        {\n           \"name\": \"areaUnderROC\",\n           \"value\": area_under_curve,\n           \"threshold\": 0.85\n        }\n    ]\n}", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "wml_models = wml_client.repository.get_details()\nmodel_uid = None\nfor model_in in wml_models['models']['resources']:\n    if MODEL_NAME == model_in['entity']['name']:\n        model_uid = model_in['metadata']['guid']\n        break\n\nif model_uid is None:\n    print(\"Storing model ...\")\n\n    published_model_details = wml_client.repository.store_model(model=model, meta_props=model_props, training_data=train_data, pipeline=pipeline)\n    model_uid = wml_client.repository.get_model_uid(published_model_details)\n    print(\"Done\")", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "model_uid", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "wml_deployments = wml_client.deployments.get_details()\ndeployment_uid = None\nfor deployment in wml_deployments['resources']:\n    if DEPLOYMENT_NAME == deployment['entity']['name']:\n        deployment_uid = deployment['metadata']['guid']\n        break\n\nif deployment_uid is None:\n    print(\"Deploying model...\")\n\n    deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, asynchronous=False)\n    deployment_uid = wml_client.deployments.get_uid(deployment)\n    \nprint(\"Model id: {}\".format(model_uid))\nprint(\"Deployment id: {}\".format(deployment_uid))", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "# Configure OpenScale", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "from ibm_ai_openscale import APIClient\nfrom ibm_ai_openscale.engines import *\nfrom ibm_ai_openscale.utils import *\nfrom ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\nfrom ibm_ai_openscale.supporting_classes.enums import *", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "### Get AI OpenScale GUID", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "import requests\n\nAIOS_GUID = None\ntoken_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': CLOUD_API_KEY\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nresources = json.loads(requests.get('https://resource-controller.cloud.ibm.com/v2/resource_instances', headers=iam_headers).text)['resources']\nfor resource in resources:\n    if \"aiopenscale\" in resource['id'].lower():\n        AIOS_GUID = resource['guid']\n        \nAIOS_CREDENTIALS = {\n    \"instance_guid\": AIOS_GUID,\n    \"apikey\": CLOUD_API_KEY,\n    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n}\n\nif AIOS_GUID is None:\n    print('AI OpenScale GUID NOT FOUND')\nelse:\n    print(AIOS_GUID)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Create schema and datamart", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "ai_client = APIClient(aios_credentials=AIOS_CREDENTIALS)\nai_client.version\ntime.sleep(20)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "### Set up datamart", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "try:\n    data_mart_details = ai_client.data_mart.get_details()\n    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n        if KEEP_MY_INTERNAL_POSTGRES:\n            print('Using existing internal datamart.')\n        else:\n            if DB_CREDENTIALS is None:\n                print('No postgres credentials supplied. Using existing internal datamart')\n            else:\n                print('Switching to external datamart')\n                ai_client.data_mart.delete(force=True)\n                ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n    else:\n        print('Using existing external datamart')\nexcept:\n    if DB_CREDENTIALS is None:\n        print('Setting up internal datamart')\n        ai_client.data_mart.setup(internal_db=True)\n    else:\n        print('Setting up external datamart')\n        ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n    ", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "data_mart_details = ai_client.data_mart.get_details()\ndata_mart_details", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Bind machine learning engines", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "binding_uid = ai_client.data_mart.bindings.add('WML instance', WatsonMachineLearningInstance(WML_CREDENTIALS))\nif binding_uid is None:\n    binding_uid = ai_client.data_mart.bindings.get_details()['service_bindings'][0]['metadata']['guid']\nbindings_details = ai_client.data_mart.bindings.get_details()\nai_client.data_mart.bindings.list()", 
            "outputs": [], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "print(binding_uid)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "ai_client.data_mart.bindings.list_assets()", 
            "outputs": [], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "## Subscriptions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Remove existing  propensity to buy subscriptions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\nfor subscription in subscriptions_uids:\n    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n    if sub_name == MODEL_NAME:\n        ai_client.data_mart.subscriptions.delete(subscription)\n        print('Deleted existing subscription for', MODEL_NAME)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n    model_uid,\n    problem_type=ProblemType.BINARY_CLASSIFICATION,\n    input_data_type=InputDataType.STRUCTURED,\n    label_column='BAD_YIELD',\n    prediction_column='predictedLabel',\n    probability_column='probability',\n    feature_columns = ['WS_001_FLOW_MEAN', 'WS_001_FLOW_MIN', 'WS_001_FLOW_MAX',\n       'WS_001_CONC_MEAN', 'WS_001_CONC_MIN', 'WS_001_CONC_MAX',\n       'DMW_FLOW_MEAN', 'DMW_FLOW_MIN', 'DMW_FLOW_MAX', 'ALK_FLOW_MEAN',\n       'ALK_FLOW_MIN', 'ALK_FLOW_MAX', 'RPM_MEAN', 'RPM_MIN', 'RPM_MAX','PLANT_A'],\n    categorical_columns = ['PLANT_A']\n))\n\nif subscription is None:\n    print('Subscription already exists; get the existing one')\n    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n    for sub in subscriptions_uids:\n        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n            subscription = ai_client.data_mart.subscriptions.get(sub)", 
            "outputs": [], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "Get subscription list", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\nai_client.data_mart.subscriptions.list()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "\nsubscription.get_details()", 
            "outputs": [], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "### Score the model so we can configure monitors", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "propensity_to_buy_scoring_endpoint = None\nprint(deployment_uid)\n\nfor deployment in wml_client.deployments.get_details()['resources']:\n    if deployment_uid in deployment['metadata']['guid']:\n        propensity_to_buy_scoring_endpoint = deployment['entity']['scoring_url']\n        \nprint(propensity_to_buy_scoring_endpoint)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "fields = ['WS_001_FLOW_MEAN', 'WS_001_FLOW_MIN', 'WS_001_FLOW_MAX',\n       'WS_001_CONC_MEAN', 'WS_001_CONC_MIN', 'WS_001_CONC_MAX',\n       'DMW_FLOW_MEAN', 'DMW_FLOW_MIN', 'DMW_FLOW_MAX', 'ALK_FLOW_MEAN',\n       'ALK_FLOW_MIN', 'ALK_FLOW_MAX', 'RPM_MEAN', 'RPM_MIN', 'RPM_MAX', 'PLANT_A']\nvalues = [[91.472265,91.591823,91.400894,29.999306,29.9453,30.0347,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.304375,5010.05,5010.61,1],\n          [91.286568,91.333725,91.225539,29.999756,29.8993,30.1047,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5011.043681,5010.74,5011.32,1],\n          [91.581607,91.677855,91.57625,30.000624,29.9481,30.0648,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5008.680625,5007.45,5009.42,0],\n          [91.332992,91.419757,91.313216,30.000023,29.9221,30.1148,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.7575,5010.47,5011.09,1],\n          [87.178007,87.376229,87.19236,65.001133,64.8447,65.1378,92.93055,92.934958,92.91834,87.957784,88.105276,87.929657,5009.978056,5009.61,5010.3,1],\n          [91.463103,91.591823,91.400894,29.999842,29.9367,30.0449,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.263889,5009.75,5010.5,0],\n          [87.284294,87.462261,87.280037,65.000094,64.9171,65.0708,92.93055,92.934958,92.91834,87.957784,88.105276,87.929657,5008.015347,5006.6,5009.73,1],\n          [87.121198,87.290196,87.104682,65.000774,64.8889,65.1762,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5009.210625,5008.67,5009.67,1],\n          [87.2452,87.462261,87.19236,62.999506,62.8072,63.167,92.682929,92.68715,92.67134,87.957784,88.105276,87.929657,5011.408889,5011.12,5011.59,0],\n          [87.099207,87.032099,87.280037,64.983894,62.8779,65.1535,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5010.101181,5009.21,5010.83,0],\n          [91.243197,91.333725,91.225539,29.998703,29.9305,30.1019,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.714444,5010.44,5011.11,1],\n          [91.612149,91.677855,91.57625,29.998469,29.9674,30.0269,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5009.607431,5008.38,5010.55,1],\n          [87.005748,87.204164,86.929326,65.001815,64.1377,65.9022,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5010.824861,5010.53,5011.05,1],\n          [91.260301,91.333725,91.225539,30.000992,29.9268,30.0831,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.054444,5009.72,5010.31,1],\n          [90.70443,90.731497,90.699472,29.513889,29.0,30.0,88.597187,88.598325,88.595852,90.464848,90.550036,90.43678,5007.784861,5006.61,5008.85,1],\n          [91.538237,91.677855,91.488572,30.000409,29.9454,30.0518,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5009.791319,5008.99,5010.11,1],\n          [87.051561,87.204164,87.017004,64.999602,64.8108,65.146,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5009.726389,5005.68,5010.44,0],\n          [91.614593,91.763888,91.57625,29.999788,29.9509,30.0482,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5008.214444,5006.21,5009.69,0],\n          [91.365367,91.419757,91.313216,30.00108,29.8762,30.1167,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,4998.986875,4996.14,5003.11,0]\n         ]\npayload_scoring = {\"fields\": fields,\"values\": values}\nscoring_response = wml_client.deployments.score(propensity_to_buy_scoring_endpoint, payload_scoring)\n\nprint(scoring_response)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Quality and feedback monitoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Enable quality monitoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Wait ten seconds to allow the payload logging table to be set up before we begin enabling monitors.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "time.sleep(20)\nsubscription.quality_monitoring.enable(threshold=0.7, min_records=100)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "### Feedback logging", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "!rm df_feedback.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_feedback.json", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "with open('df_feedback.json') as feedback_file:\n    df_feedback = json.load(feedback_file)\nsubscription.feedback_logging.store(df_feedback)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription.feedback_logging.show_table()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "run_details = subscription.quality_monitoring.run()\nstatus = run_details['status']\nid = run_details['id']\nprint(id)\n\nprint(\"Run status: {}\".format(status))\n\nstart_time = time.time()\nelapsed_time = 0\n\nwhile status != 'completed' and elapsed_time < 60:\n    time.sleep(10)\n    run_details = subscription.quality_monitoring.get_run_details(run_uid=id)\n    status = run_details['status']\n    elapsed_time = time.time() - start_time\n    print(\"Run status: {}\".format(status))", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription.quality_monitoring.get_run_details()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription.quality_monitoring.show_table()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "subscription.quality_monitoring._get_data_from_rest_api()", 
            "cell_type": "markdown", 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "ai_client.data_mart.get_deployment_metrics()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Fairness monitoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription.fairness_monitoring.enable(\n            features=[\n                Feature(\"PLANT_A\", majority=[[1,1]], minority=[[0,0]], threshold=0.95)\n            ],\n            favourable_classes=['GOOD'],\n            unfavourable_classes=['BAD'],\n            min_records=1000,\n            training_data=df_training\n        )", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Score the model again now that monitoring is configured", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "!rm df_payload_biased.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_payload_biased.json", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "Score 1000 randomly chosen records", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "import random\n\nwith open('df_payload_biased.json', 'r') as scoring_file:\n    scoring_data = json.load(scoring_file)\n\nfields = scoring_data['fields']\nvalues = []\nfor _ in range(1000):\n    values.append(random.choice(scoring_data['values']))\npayload_scoring = {\"fields\": fields, \"values\": values}\n\nscoring_response = wml_client.deployments.score(propensity_to_buy_scoring_endpoint, payload_scoring)\nprint(scoring_response)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription.get_details()", 
            "outputs": [], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "# Insert historical payloads", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "!rm payload_history*.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_1.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_2.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_3.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_4.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_5.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_6.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_7.json", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "historyDays = 7\nfrom ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\nimport datetime\nimport time", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "\n\nfor day in range(historyDays):\n    print('Loading day {}'.format(day + 1))\n    history_file = 'payload_history_' + str(day + 1) + '.json'\n    with open(history_file) as f:\n        payloads = json.load(f)\n        hourly_records = int(len(payloads) / 24)\n        index = 0\n        for hour in range(24):\n            recordsList = []\n            for i in range(hourly_records):\n                score_time = str(datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1))))\n                recordsList.append(PayloadRecord(request=payloads[index]['request'], response=payloads[index]['response'], scoring_timestamp=score_time))\n                index += 1\n            subscription.payload_logging.store(records=recordsList)\nprint('Finished')", 
            "cell_type": "raw", 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "data_mart_id = subscription.get_details()['metadata']['url'].split('/service_bindings')[0].split('marts/')[1]\nprint(data_mart_id)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "performance_metrics_url = 'https://api.aiopenscale.cloud.ibm.com' + subscription.get_details()['metadata']['url'].split('/service_bindings')[0] + '/metrics'\nprint(performance_metrics_url)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Insert historical fairness metrics", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "!rm fairness_records.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/fairness_records.json\nimport random", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "\ntoken_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': AIOS_CREDENTIALS['apikey']\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nwith open('fairness_records.json', 'r') as history_file:\n    payloads = json.load(history_file)\n\nfor day in range(historyDays):\n    print('Day', day + 1)\n    for hour in range(24):\n        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n        \n        qualityMetric = {\n            'metric_type': 'fairness',\n            'binding_id': binding_uid,\n            'timestamp': score_time,\n            'subscription_id': model_uid,\n            'asset_revision': model_uid,\n            'deployment_id': deployment_uid,\n            'value': random.choice(payloads)\n        }\n\n        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers)\nprint('Finished')", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Insert historical quality metrics", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "token_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': AIOS_CREDENTIALS['apikey']\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nmeasurements = [0.94, 0.91, 0.78, 0.82, 0.90, 0.94, 0.93]\nfor day in range(historyDays):\n    print('Day', day + 1)\n    for hour in range(24):\n        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n        \n        qualityMetric = {\n            'metric_type': 'quality',\n            'binding_id': binding_uid,\n            'timestamp': score_time,\n            'subscription_id': model_uid,\n            'asset_revision': model_uid,\n            'deployment_id': deployment_uid,\n            'value': {\n                'quality': measurements[day],\n                'threshold': 0.85,\n                'metrics': [\n                    {\n                        'name': 'auroc',\n                        'value': measurements[day],\n                        'threshold': 0.75\n                    }\n                ]\n            }\n        }\n\n        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers)\nprint('Finished')", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Insert historical performance metrics", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "token_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': AIOS_CREDENTIALS['apikey']\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nfor day in range(historyDays):\n    print('Day', day + 1)\n    for hour in range(24):\n        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n        score_count = random.randint(600, 6000)\n        score_resp = random.uniform(600, 3000)\n\n        performanceMetric = {\n            'metric_type': 'performance',\n            'binding_id': binding_uid,\n            'timestamp': score_time,\n            'subscription_id': model_uid,\n            'asset_revision': model_uid,\n            'deployment_id': deployment_uid,\n            'value': {\n                'response_time': score_resp,\n                'records': score_count\n            }\n        }\n\n        response = requests.post(performance_metrics_url, json=[performanceMetric], headers=iam_headers)\nprint('Finished')", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Configure Explainability", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "pd_data.head()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "from ibm_ai_openscale.supporting_classes import *\nsubscription.explainability.enable(training_data=df_training)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription.explainability.get_details()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Run fairness monitor", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Kick off a fairness monitor run on current data. Depending on how fast the monitor runs, the table may not contain the most recent results.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "run_details = subscription.fairness_monitoring.run()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "subscription.fairness_monitoring.show_table()", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Additional data to help debugging", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "#print('Datamart:', data_mart_id)\nprint('Model:', model_uid)\nprint('Deployment:', deployment_uid)\nprint('Binding:', binding_uid)\nprint('Scoring URL:', propensity_to_buy_scoring_endpoint)", 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Identify transactions for Explainability", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Transaction IDs identified by the cells below can be copied and pasted into the Explainability tab of the OpenScale dashboard.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "import json, random\n\nDEPLOYMENT_NAME = \"Yieldx Model\"\nMIN_RECORDS = 1000\nMAX_RECORDS = 1000", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "!rm df_payload_biased.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_payload_biased.json", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "wml_deployments = wml_client.deployments.get_details()\nscoring_url = None\nfor deployment in wml_deployments['resources']:\n    if DEPLOYMENT_NAME == deployment['entity']['name']:\n        scoring_url = deployment['entity']['scoring_url']\n        break\n    \nprint(\"Scoring URL: {}\".format(scoring_url))", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "try:\n    with open('df_payload_biased.json', 'r') as scoring_file:\n        scoring_data = json.load(scoring_file)\n    print('file found')\n    \nexcept:\n    !wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_payload_biased.json\n    with open('df_payload_biased.json', 'r') as scoring_file:\n        scoring_data = json.load(scoring_file)\n    print('file downloaded')\n", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "fields = scoring_data['fields']\nvalues = []\nfor _ in range(0, random.randint(MIN_RECORDS, MAX_RECORDS)):\n    values.append(random.choice(scoring_data['values']))\npayload_scoring = {\"fields\": fields, \"values\": values}\n\nscoring_response = wml_client.deployments.score(scoring_url, payload_scoring)\nprint(scoring_response)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "time.sleep(10)\npayload_data = subscription.payload_logging.get_table_content(limit=200)\npayload_data.filter(items=['scoring_id', 'predictedLabel', 'probability','PLANT_A'])", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Congratulations!\n\nYou have finished the hands-on lab for IBM Watson OpenScale. You can now view the [OpenScale Dashboard](https://aiopenscale.cloud.ibm.com/). Click on the tile for the Propensity to Buy model to see fairness, accuracy, and performance monitors. Click on the timeseries graph to get detailed information on transactions during a specific time window.\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}